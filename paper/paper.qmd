---
title: "My title"
subtitle: "My subtitle if needed"
author: 
  - First author
  - Another author
thanks: "Code and data are available at: [https://github.com/RohanAlexander/starter_folder](https://github.com/RohanAlexander/starter_folder)."
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(palmerpenguins)
```


# Introduction

Overview paragraph

Estimand paragraph

Results paragraph

Why it matters paragraph

Telegraphing paragraph: The remainder of this paper is structured as follows. @sec-data....






# Data {#sec-data}

## Overview

We use the statistical programming language R [@citeR].... Our data [@shelter].... Following @tellingstories, we consider...

Overview text

## Measurement
	
Some paragraphs about how we go from a phenomena in the world to an entry in the dataset.

## Outcome variables

Add graphs, tables and text. Use sub-sub-headings for each outcome variable or update the subheading to be singular.



Some of our data is of penguins (@fig-bills), from @palmerpenguins.

```{r}
#| label: fig-bills
#| fig-cap: Bills of penguins
#| echo: false

ggplot(penguins, aes(x = island, fill = species)) +
  geom_bar(alpha = 0.8) +
  scale_fill_manual(values = c("darkorange","purple","cyan4"),
                    guide = "none") +
  theme_minimal() +
  facet_wrap(~species, ncol = 1) +
  coord_flip()
```

Talk more about it.

And also planes (@fig-planes). (You can change the height and width, but don't worry about doing that until you have finished every other aspect of the paper - Quarto will try to make it look nice and the defaults usually work well once you have enough text.)

```{r}
#| label: fig-planes
#| fig-cap: Relationship between wing length and width
#| echo: false
#| warning: false
#| message: false

analysis_data <- read_csv(here::here("data/02-analysis_data/analysis_data.csv"))

analysis_data |> 
  ggplot(aes(x = width, y = length)) +
  geom_point(alpha = 0.8) +
  theme_minimal() +
  labs(x = "Wing width (mm)",
       y = "Wing length (mm)")
```

Talk way more about it. 

## Predictor variables

Add graphs, tables and text.

Use sub-sub-headings for each outcome variable and feel free to combine a few into one if they go together naturally.








# Model

The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in [Appendix -@sec-model-details].

## Model set-up

In our study, we aim to predict who will win the 2024 US Presidential Electionâ€”Donald Trump or Kamala Harris. We use a dataset gathered from upcoming polls that has been carefully cleaned to make sure our predictions are accurate. Because predicting election results can be complex and influenced by many changing factors, we have decided to use a linear regression model.

We apply the `lm` function in the `R` software [@citeR] to create our linear regression model. This method lets us look at how many people support Donald John Trump as a percentage, assuming we have enough data to treat this percentage as continuous. Our model looks at how four main factors might affect Trump's support; these factors are explained in the methods part of our study.Linear regression is especially useful for our analysis because it is simple and the results are easy to understand. It helps us clearly show how much each factor affects the election results, which helps us see what most influences how people vote.

For more details about how the model is set up, including the checks we do to make sure it works right and other analyses, please look at the appendix. This part of our report makes sure our results are strong by fully describing the tests and checks we do, confirming our predictions are reliable.

$$
\begin{aligned}
y_i | \mu_i & \sim \text{Normal}(\mu_i, \sigma) \\
\mu_i &= \beta_0 + \beta_1 \times \text{age}_i + \beta_2 \times \text{Income}_i + \beta_3 \times \text{Education level}_i + \beta_4 \times \text{State}_i \\
\beta_0 & \sim \text{Normal}(0, 2.5) \\
\beta_1 & \sim \text{Normal}(0, 2.5) \\
\beta_2 & \sim \text{Normal}(0, 2.5) \\
\beta_3 & \sim \text{Normal}(0, 2.5) \\
\beta_4 & \sim \text{Normal}(0, 2.5) \\
\sigma & \sim \text{Exponential}(1)
\end{aligned}
$$
Explanation of Changes and Model Components:

$y_i$: Represents the proportion of respondents who support Donald Trump. This shift changes the target variable but the model's structure remains suitable for predicting a proportion as a continuous outcome.
$\mu_i$: Represents the expected proportion of support for Trump given the predictors. This linear combination of predictors adjusts the model's focus to align with the support dynamics for Trump.
Predictors: The model now explicitly uses age, Income, Education level, and State as predictors. These reflect more directly measurable and common factors that might influence election support patterns:
$\beta_1$ (age): Might capture variations in political preference across different age groups.
$\beta_2$ (Income): Allows the model to assess how economic status influences political preferences.
$\beta_3$ (Education level): Could indicate how educational backgrounds affect support.
$\beta_4$ (State): Accounts for geographical variations in support, which are critical in U.S. elections.
Priors:
Intercept and Coefficients: All coefficients, including the intercept, continue to assume a normal prior with a mean of 0 and a standard deviation of 2.5, implying no initial bias towards any outcome.
$\sigma$: The standard deviation of the residuals assumes an exponential prior, which suggests that large deviations from the observed proportions of support are considered improbable, maintaining a focus on tighter prediction intervals.



### Model justification

We expect a positive relationship between the size of the wings and time spent aloft. In particular...

We can use maths by including latex between dollar signs, for instance $\theta$.


# Results

Our results are summarized in @tbl-modelresults.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

library(rstanarm)

first_model <-
  readRDS(file = here::here("models/first_model.rds"))
```

```{r}
#| echo: false
#| eval: true
#| label: tbl-modelresults
#| tbl-cap: "Explanatory models of flight time based on wing width and wing length"
#| warning: false

modelsummary::modelsummary(
  list(
    "First model" = first_model
  ),
  statistic = "mad",
  fmt = 2
)
```




# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}

# Methodology 
1200 sample of registered voters

#Online survey

# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]

pp_check(first_model) +
  theme_classic() +
  theme(legend.position = "bottom")

posterior_vs_prior(first_model) +
  theme_minimal() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") +
  coord_flip()
```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

plot(first_model, "trace")

plot(first_model, "rhat")
```



\newpage

# Appendix 1

## Population, Frame, and Sample
YouGov conducted surveys with adults in the U.S. who have internet access. They used their online group of people as the sample frame. This frame covers a wide population. For each survey, the sample includes people from this group who fit specific requirements set for that survey. This helps collect data that targets certain information.

## Sample Recruitment
YouGov worked actively to bring people into their panel. They used different ways of advertising and worked with various partners across many types of media. This method aimed to gather a wide range of people. This helps make sure the group of survey takers represents many different kinds of people in the U.S. However, it mostly includes people who can use the internet.

## Sampling Methodology
YouGov used a non-probability method to find people for their online panel through various media sources. This helps improve how well the panel represents different groups of people. This method is fast and lets them interact with the survey takers through surveys that can include videos and pictures. But, relying on people who choose to join and using digital surveys might limit who takes part and affect the survey's accuracy. They made the survey results match the general population by adjusting weights according to certain standards.

## Handling Non-Response
They managed the issue of people not responding to surveys by adjusting the survey sample's make-up. They did this using weights based on well-known data like the U.S. Census.

## Questionnaire Design
YouGov designed their questionnaires to be easy to access and interesting, often using videos and pictures to give more information. However, using digital formats might stop people with limited internet skills or access from taking part.



# References


